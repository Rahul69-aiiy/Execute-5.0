# -*- coding: utf-8 -*-
"""water_electricity_optimization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CO7H6IjyMHIZsQUnwgSNBExFJ8-Uo9Dr
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""Creating dataset

"""

np.random.seed(42)
start_date = "2023-01-01"
days = 365
area_id = "A101"
population = 4200
time_slots = ["Morning", "Afternoon", "Evening"]
dates = pd.date_range(start=start_date, periods=days)

data = []
for date in dates:
    temp = np.random.normal(loc=30, scale=4)

    for slot in time_slots:
        if slot == "Morning":
            electricity = np.random.normal(120, 20)
            water = np.random.normal(900, 150)
        elif slot == "Afternoon":
            electricity = np.random.normal(180, 30)
            water = np.random.normal(1200, 200)
        else:
            electricity = np.random.normal(220, 35)
            water = np.random.normal(1500, 250)

        elec_pc = electricity / population
        water_pc = water / population

        optimized = int(elec_pc <= 0.06 and water_pc <= 0.35)

        data.append([
            date.date(),
            area_id,
            slot,
            round(electricity, 2),
            round(water, 2),
            round(temp, 1),
            population,
            optimized
        ])

columns = [
    "Date",
    "Area_ID",
    "TimeSlot",
    "Electricity_kWh",
    "Water_Liters",
    "Temp",
    "Population",
    "Optimized"
]
df = pd.DataFrame(data, columns=columns)
df.to_csv("electricity_water_optimization_365_days.csv", index=False)
df.head()

"""EDA

"""

df = pd.read_csv("electricity_water_optimization_365_days.csv")
df["Date"] = pd.to_datetime(df["Date"])
df = df.sort_values(["Area_ID", "Date"])

print(df.info())
df['Optimized'].value_counts(normalize=True)

df.groupby("TimeSlot")["Electricity_kWh"].mean()

df.groupby("TimeSlot")["Water_Liters"].mean()

df["DayOfWeek"] = df["Date"].dt.dayofweek
df["Month"] = df["Date"].dt.month
df["Weekend"] = df["DayOfWeek"].isin([5,6]).astype(int)

df["Elec_per_capita"] = df["Electricity_kWh"] / df["Population"]
df["Water_per_capita"] = df["Water_Liters"] / df["Population"]

df = df.sort_values(["Area_ID", "TimeSlot", "Date"])

df["Elec_lag_1"] = df.groupby(["Area_ID","TimeSlot"])["Electricity_kWh"].shift(1)
df["Water_lag_1"] = df.groupby(["Area_ID","TimeSlot"])["Water_Liters"].shift(1)

df["Elec_roll_7"] = (
    df.groupby(["Area_ID","TimeSlot"])["Electricity_kWh"]
      .rolling(7).mean()
      .reset_index(level=[0, 1], drop=True)
)

df["Water_roll_7"] = (
    df.groupby(["Area_ID","TimeSlot"])["Water_Liters"]
      .rolling(7).mean()
      .reset_index(level=[0, 1], drop=True)
)

df[["Elec_roll_7", "Water_roll_7"]].isna().sum()

df = df.dropna(subset=[
    "Elec_lag_1",
    "Water_lag_1",
    "Elec_roll_7",
    "Water_roll_7"
])

df.columns.tolist()

# Ensure TimeSlot is categorical with all expected values
df["TimeSlot"] = pd.Categorical(
    df["TimeSlot"],
    categories=["Morning", "Afternoon", "Evening"]
)

# One-hot encode
df = pd.get_dummies(
    df,
    columns=["TimeSlot"],
    prefix="TimeSlot",
    drop_first=False
)

df

df.filter(like="TimeSlot_").columns

target = "Optimized"

features = [
    "Area_ID",
    "Electricity_kWh",
    "Water_Liters",
    "Temp",
    "Population",
    "DayOfWeek",
    "Month",
    "Weekend",
    "Elec_per_capita",
    "Water_per_capita",
    "Elec_lag_1",
    "Water_lag_1",
    "Elec_roll_7",
    "Water_roll_7",
    "TimeSlot_Morning",
    "TimeSlot_Afternoon",
    "TimeSlot_Evening"
]

set(features) - set(df.columns)

df = df.dropna().reset_index(drop=True)

split_date = df["Date"].quantile(0.8)

train_idx = df["Date"] < split_date
test_idx  = df["Date"] >= split_date

X_train = df.loc[train_idx, features]
y_train = df.loc[train_idx, "Optimized"]

X_test  = df.loc[test_idx, features]
y_test  = df.loc[test_idx, "Optimized"]

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df["Area_ID"] = le.fit_transform(df["Area_ID"])

from xgboost import XGBClassifier

model = XGBClassifier(
    n_estimators=300,
    max_depth=6,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    objective="binary:logistic",
    eval_metric="logloss",
    random_state=42
)

model.fit(X_train, y_train)

from sklearn.metrics import classification_report, roc_auc_score

y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:, 1]

print(classification_report(y_test, y_pred))
print("ROC-AUC:", roc_auc_score(y_test, y_prob))

import pandas as pd

importance = pd.Series(
    model.feature_importances_,
    index=features
).sort_values(ascending=False)

importance.head(20)

leak_features = [
    "Elec_lag_1",
    "Water_lag_1",
    "Elec_roll_7",
    "Water_roll_7"
]

y_train_shuffled = y_train.sample(frac=1.0, random_state=42)

model.fit(X_train, y_train_shuffled)
roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])

"""Exporting the model"""

import joblib

artifact = {
    "model": model,
    "area_encoder": le,
    "features": features,
    "threshold": 0.5
}

joblib.dump(artifact, "resource_optimization_model.joblib")

loaded = joblib.load("resource_optimization_model.joblib")

loaded_model = loaded["model"]
loaded_features = loaded["features"]

# Test one prediction
loaded_model.predict(X_test[loaded_features].iloc[:5])

